{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np \n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Reshape\n",
    "import keras.backend as k_backend\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e652d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files \n",
    "base_path = \"./../data/\"\n",
    "files = [os.path.join(\"{}{}\".format(base_path,i)) for i in os.listdir(base_path) if os.path.exists(\"{}{}\".format(base_path,i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e06b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    " # get single sample and label from dataframe\n",
    "def get_single_sample(df_sub):\n",
    "    x1, x2, y1, y2 = df_sub[\"bbox_x1\"], df_sub[\"bbox_x2\"], df_sub[\"bbox_y1\"], df_sub[\"bbox_y2\"]\n",
    "    xc, yc = (x1 + 2)/2, (y1+y2)/2\n",
    "    width, height = x2 - x1 , y2 - y1\n",
    "    r, g, b = df_sub[\"median_r\"], df_sub[\"median_g\"], df_sub[\"median_b\"]\n",
    "    h, s, v = df_sub[\"median_h\"], df_sub[\"median_s\"], df_sub[\"median_v\"]\n",
    "    stype = df_sub['type']\n",
    "    sample = np.vstack( ( x1, x2, y1, y2, r, g, b, h, s, v, stype ) ).T \n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def get_single_label(df_label):\n",
    "    x1, x2, y1, y2 = df_label[\"bbox_x1\"], df_label[\"bbox_x2\"], df_label[\"bbox_y1\"], df_label[\"bbox_y2\"]\n",
    "    xc, yc = (x1 + 2)/2, (y1+y2)/2\n",
    "    width, height = x2 - x1 , y2 - y1\n",
    "    r, g, b = df_label[\"mean_r\"], df_label[\"mean_g\"], df_label[\"mean_b\"]\n",
    "    stype = df_label['type']\n",
    "    label = np.vstack( ( x1, x2, y1, y2  ) ).T\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "look_back = 4 # input time length\n",
    "look_forward = 1 # output time length\n",
    "\n",
    "x_dataset = []\n",
    "y_dataset = []\n",
    "\n",
    "for f in files: \n",
    "    \n",
    "    df = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "    if len(df) > look_back + look_forward: \n",
    "\n",
    "        for i in range( len(df) - look_back - look_forward ): \n",
    "\n",
    "            df_sub = df.iloc[i: i+look_back]\n",
    "            df_label = df.iloc[i+look_back: i+look_back+look_forward]\n",
    "\n",
    "            # train set\n",
    "            sample = get_single_sample(df_sub)\n",
    "            x_dataset.append( sample )\n",
    "\n",
    "            # test set\n",
    "            label = get_single_label(df_label)\n",
    "            y_dataset.append(label)\n",
    "            \n",
    "# prepared dataset\n",
    "x_dataset = np.array(x_dataset)\n",
    "y_dataset = np.array(y_dataset)\n",
    "\n",
    "print (\"Total Data: \", x_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test and validation sets \n",
    "n = x_dataset.shape[0] \n",
    "\n",
    "X_train, y_train = x_dataset[0 : int(0.7*n)], y_dataset[0 : int(0.7 * n)]\n",
    "X_test, y_test = x_dataset[int(0.7*n) : int(0.9*n)], y_dataset[int(0.7 * n) : int(0.9*n)]\n",
    "X_val, y_val = x_dataset[int(0.9*n) : ], y_dataset[int(0.9*n) : ]\n",
    "\n",
    "\n",
    "print (\"Train Dataset: \", X_train.shape, y_train.shape)\n",
    "print (\"Test Dataset: \", X_test.shape, y_test.shape)\n",
    "print (\"Validation Dataset: \", X_val.shape, y_val.shape)\n",
    "print (\"-\"*50)\n",
    "\n",
    "print (\"Sample Train Dataset: \", X_train[0].shape, y_train[0].shape)\n",
    "print (\"Sample Test Dataset: \", X_test[0].shape, y_test[0].shape)\n",
    "print (\"Sample Validation Dataset: \", X_val[0].shape, y_val[0].shape)\n",
    "print (\"-\"*50)\n",
    "\n",
    "print (\"Train Max/Min | Mean | Std.: \", np.max(X_train), np.min(X_train), np.mean(X_train), np.std(X_train),  )\n",
    "print (\"Test Max/Min | Mean | Std.: \", np.max(X_test), np.min(X_test), np.mean(X_test), np.std(X_test) )\n",
    "print (\"Val Max/Min | Mean | Std.: \", np.max(X_val), np.min(X_val), np.mean(X_val), np.std(X_val) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE custom loss - not really used.\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return k_backend.sqrt(k_backend.mean(k_backend.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "n_features = X_train.shape[2]\n",
    "n_neurons = 200\n",
    "n_epochs = 250\n",
    "n_out_features = y_train.shape[-1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add( LSTM(n_neurons, input_shape=(look_back, n_features), return_sequences = True, name=\"lstm-1-layer\")) \n",
    "model.add( LSTM(int(n_neurons/2), return_sequences = False  , activation = \"relu\", name = \"lstm-2-layer\") )\n",
    "model.add( Dense(look_forward*n_out_features, activation = \"sigmoid\" , name = \"dense-layer\") )\n",
    "model.add( Reshape([look_forward, n_out_features], name = \"reshape-layer\") )\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# model.compile(loss=root_mean_squared_error, optimizer='adam', metrics=['accuracy', 'mse', 'mae', root_mean_squared_error])\n",
    "# model.compile(loss=\"mae\", optimizer='adam', metrics=['accuracy', 'mse', 'mae'])\n",
    "model.compile(loss=\"mse\", optimizer='adam', metrics=['accuracy', 'mse', 'mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=50)\n",
    "\n",
    "history = model.fit(\n",
    "    x = X_train, y = y_train,\n",
    "    epochs=n_epochs, \n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    "    # callbacks=[early_stopping, reduce_lr],\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (history.history.keys())\n",
    "# plot model training history\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title(\"Loss (MSE)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['mse'], label='train')\n",
    "plt.plot(history.history['val_mse'], label='val')\n",
    "plt.title(\"MSE\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['mae'], label='train')\n",
    "plt.plot(history.history['val_mae'], label='val')\n",
    "plt.title(\"MAE\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"./rnn_{}}_lookback_{}_lookahead_{}_features_in_{}_features_out.png\".format(look_back, look_forward, n_features, n_out_features))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_predictions  = model.predict(X_test)\n",
    "print (y_predictions.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89222c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple check\n",
    "print (\"Predicted: \\n\", y_predictions[0])\n",
    "print (\"-\"*50)\n",
    "print (\"Real: \\n\", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a488a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation metrics\n",
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    corr = np.corrcoef( np.squeeze(forecast), np.squeeze(actual) )[0,1]   # corr\n",
    "    \n",
    "    return({'mape':mape*100, 'me':me, 'mae': mae,  'rmse':rmse, \n",
    "            'corr':corr})\n",
    "\n",
    "\n",
    "for i in range(n_out_features):\n",
    "    out = (forecast_accuracy( y_predictions[:,:,i], y_test[:,:,i] ))\n",
    "    print (\"Feature : {}\".format(i+1))\n",
    "    print (\"MAPE:\\t\", out[\"mape\"], \" %\")\n",
    "    print (\"ME:\\t\", out[\"me\"])\n",
    "    print (\"MAE:\\t\", out[\"mae\"])\n",
    "    print (\"RMSE:\\t\", out[\"rmse\"])\n",
    "    print (\"CORR:\\t\", out[\"corr\"])\n",
    "    print (\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on random sets.\n",
    "random_n = np.random.randint( X_test.shape[0]  )\n",
    "\n",
    "test_y, label_y, predict_y = X_test[random_n], y_test[random_n], y_predictions[random_n]\n",
    "\n",
    "test_x = np.linspace( 0, look_back , num = look_back )\n",
    "label_x = np.arange( look_back + 1, look_forward + look_back + 1 , 1 )\n",
    "\n",
    "\n",
    "plt.figure(figsize = (42, 6))\n",
    "for i in range(n_out_features):\n",
    "    plt.subplot(1, n_features+1, i+1)\n",
    "    plt.plot(test_x, test_y[:, i] , '-r', label = \"input\" ) \n",
    "    plt.plot(label_x, label_y[:, i] , '-xb', label = \"actual\" )\n",
    "    plt.plot(label_x, predict_y[:, i]  , '-og', label = \"predicted\" )\n",
    "    plt.title(\"Feature: {}\".format(i+1))\n",
    "    plt.ylim([np.min(test_y[:,i]) - 0.05, np.max(test_y[:,i]) + 0.05 ])\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block takes a random file and \n",
    "# predicts the future bbox (x1, x2, y1, y2) \n",
    "\n",
    "# model.save (\"./../../models/berry_lstm_in_feature_11_out_feature_4_look_back_4_look_ahead_1_n_epochs_250.h5\")\n",
    "# model = keras.models.load_model(\"./../../models/berry_lstm_in_feature_11_out_feature_4_look_back_4_look_ahead_1_n_epochs_250.h5\")\n",
    "\n",
    "# test on random sets.\n",
    "random_n =  np.random.randint( len(files) )\n",
    "df_sub = pd.read_csv(files[random_n], sep='\\t')\n",
    "\n",
    "# train set\n",
    "sample = get_single_sample( df_sub )\n",
    "sample_real = get_single_sample (df_sub)\n",
    "\n",
    "predicted_values = []\n",
    "\n",
    "for i in range(look_back):\n",
    "    predicted_values.append([0,0,0,0])\n",
    "\n",
    "for i in range(sample.shape[0] - look_back ):\n",
    "    \n",
    "    seq = sample[i : i + look_back]  \n",
    "    y_predict = model.predict( np.expand_dims( seq , axis=0), verbose=0)  \n",
    "    predicted_values.append( y_predict.squeeze().tolist() )\n",
    "\n",
    "    # For teacher forcing. Otherwise comment this.\n",
    "    sample[i+look_back, 0:4] = y_predict.squeeze().tolist()\n",
    "\n",
    "\n",
    "\n",
    "# this plots predictions\n",
    "predicted_values = np.array( predicted_values )\n",
    "feature_names = [\"x1\", \"x2\", \"y1\", \"y2\"]\n",
    "\n",
    "plt.figure(12, figsize=(16,6))\n",
    "for i in range(n_out_features):\n",
    "\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot( sample_real[:, i] , 'rx--', label=\"Real {}\".format(feature_names[i]))\n",
    "\n",
    "    # For teacher forcing. otherwise comment this.\n",
    "    plt.plot( sample[:, i] , 'go--', label=\"Pred {}\".format(feature_names[i]))\n",
    "\n",
    "    # For normal prediction, \n",
    "    # plt.plot( predicted_values[:, i] , 'go--', label=\"Pred {}\".format(feature_names[i]))\n",
    "    plt.legend()\n",
    "\n",
    "    # this gets used in the next block to visualize the predicted bbox.   \n",
    "    df_sub['predicted_{}'.format(feature_names[i])] = predicted_values[:,i]\n",
    "\n",
    "\n",
    "# this plots features \n",
    "other_features = [ \n",
    "    ['mean_r', 'mean_g','mean_b', 'type'], ['median_r', 'median_g','median_b', 'type'],\n",
    "    ['mean_h', 'mean_s','mean_v', 'type'], ['median_h', 'median_s','median_v', 'type'],\n",
    "    ['type'], [ 'bbox_y1', 'bbox_y2','type','type',] \n",
    "]\n",
    "\n",
    "colors = ['rx--', 'gx--', 'bx--', 'k']\n",
    "\n",
    "plt.figure(13, figsize=(16,6))\n",
    "\n",
    "for i in range( len(other_features) ):\n",
    "\n",
    "    if len(other_features) % 2 == 0:\n",
    "        plt.subplot( int (len(other_features)/2) ,2 , i+1 )\n",
    "    else:\n",
    "        plt.subplot( len(other_features),1, i+1 )\n",
    "\n",
    "    for count, feature in enumerate( other_features[i] ):\n",
    "        plt.plot(  df_sub[ feature] , colors[count], label=feature )\n",
    "        plt.legend()\n",
    "        plt.ylim([-0.1,1.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the path 'img_folder'\n",
    "\n",
    "img_folder = \"/path/to/raw/images\"\n",
    "\n",
    "for i in range(len(df_sub)):\n",
    "    row = df_sub.iloc[i]\n",
    "\n",
    "    img_path = os.path.join( img_folder, \"{}{}\".format(row['filename'], '.png') )\n",
    "    if os.path.exists(img_path):\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = imutils.resize(img, width = 640)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # plot label\n",
    "        x1, x2, y1, y2 = int(row['bbox_x1'] * w), int(row['bbox_x2'] * w), int (row['bbox_y1'] * h), int(row['bbox_y2'] * h)\n",
    "        cv2.rectangle( img, (x1,y1), (x2, y2), (0, 0, 255), 2 )\n",
    "\n",
    "        # plot label\n",
    "        px1, px2, py1, py2 = int(row['predicted_x1'] * w), int(row['predicted_x2'] * w), int (row['predicted_y1'] * h), int(row['predicted_y2'] * h)\n",
    "        cv2.rectangle( img, (px1,py1), (px2, py2), (0, 255, 0), 2 )\n",
    "        \n",
    "        cv2.imshow('image', img)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
